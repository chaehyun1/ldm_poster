{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/                         new_dataset.py  \u001b[01;34mresults\u001b[0m/\n",
      "\u001b[01;34mdenoising_diffusion_pytorch\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/    train.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:43<00:00, 1138.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from new_dataset import *\n",
    "\n",
    "data = DatasetSVD('Cifar-10') # cifar10\n",
    "images, labels = data.get_svd()\n",
    "custom_dataset = CustomDataset(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lucidrains/denoising-diffusion-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    }
   ],
   "source": [
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    flash_attn = True\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 32, # 이미지 사이즈 맞춰서 \n",
    "    timesteps = 1000    # number of steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Robust FID computation requires a lot of generated samples and can therefore be very time consuming.Consider using DDIM sampling to save time.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "diffusion,\n",
    "custom_dataset,\n",
    "train_batch_size = 32,\n",
    "train_lr = 8e-5,\n",
    "train_num_steps = 1000,         # total training steps 700000\n",
    "gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "ema_decay = 0.995,                # exponential moving average decay\n",
    "amp = True,                       # turn on mixed precision\n",
    "calculate_fid = True              # whether to calculate fid during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffusion_model,\n",
    "        folder = \"dataloader\",\n",
    "        *,\n",
    "        train_batch_size = 16,\n",
    "        gradient_accumulate_every = 1,\n",
    "        augment_horizontal_flip = True,\n",
    "        train_lr = 1e-4,\n",
    "        train_num_steps = 100000,\n",
    "        ema_update_every = 10,\n",
    "        ema_decay = 0.995,\n",
    "        adam_betas = (0.9, 0.99),\n",
    "        save_and_sample_every = 1000,\n",
    "        num_samples = 25,\n",
    "        results_folder = './results',\n",
    "        amp = False,\n",
    "        mixed_precision_type = 'fp16',\n",
    "        split_batches = True,\n",
    "        convert_image_to = None,\n",
    "        calculate_fid = True,\n",
    "        inception_block_idx = 2048,\n",
    "        max_grad_norm = 1.,\n",
    "        num_fid_samples = 50000,\n",
    "        save_best_and_latest_only = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # accelerator\n",
    "\n",
    "        self.accelerator = Accelerator(\n",
    "            split_batches = split_batches,\n",
    "            mixed_precision = mixed_precision_type if amp else 'no'\n",
    "        )\n",
    "\n",
    "        # model\n",
    "\n",
    "        self.model = diffusion_model\n",
    "        self.channels = diffusion_model.channels\n",
    "        is_ddim_sampling = diffusion_model.is_ddim_sampling\n",
    "\n",
    "        # default convert_image_to depending on channels\n",
    "\n",
    "        if not exists(convert_image_to):\n",
    "            convert_image_to = {1: 'L', 3: 'RGB', 4: 'RGBA'}.get(self.channels)\n",
    "\n",
    "        # sampling and training hyperparameters\n",
    "\n",
    "        assert has_int_squareroot(num_samples), 'number of samples must have an integer square root'\n",
    "        self.num_samples = num_samples\n",
    "        self.save_and_sample_every = save_and_sample_every\n",
    "\n",
    "        self.batch_size = train_batch_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "        assert (train_batch_size * gradient_accumulate_every) >= 16, f'your effective batch size (train_batch_size x gradient_accumulate_every) should be at least 16 or above'\n",
    "\n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.image_size = diffusion_model.image_size\n",
    "\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "\n",
    "        # dataset and dataloader\n",
    "\n",
    "        #self.ds = Dataset(folder, self.image_size, augment_horizontal_flip = augment_horizontal_flip, convert_image_to = convert_image_to)\n",
    "        self.ds = folder\n",
    "        assert len(self.ds) >= 100, 'you should have at least 100 images in your folder. at least 10k images recommended'\n",
    "\n",
    "        dl = DataLoader(self.ds, batch_size = train_batch_size, shuffle = True, pin_memory = True, num_workers = cpu_count())\n",
    "\n",
    "        dl = self.accelerator.prepare(dl)\n",
    "        self.dl = cycle(dl)\n",
    "\n",
    "        # optimizer\n",
    "\n",
    "        self.opt = Adam(diffusion_model.parameters(), lr = train_lr, betas = adam_betas)\n",
    "\n",
    "        # for logging results in a folder periodically\n",
    "\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema = EMA(diffusion_model, beta = ema_decay, update_every = ema_update_every)\n",
    "            self.ema.to(self.device)\n",
    "\n",
    "        self.results_folder = Path(results_folder)\n",
    "        self.results_folder.mkdir(exist_ok = True)\n",
    "\n",
    "        # step counter state\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        # prepare model, dataloader, optimizer with accelerator\n",
    "\n",
    "        self.model, self.opt = self.accelerator.prepare(self.model, self.opt)\n",
    "\n",
    "        # FID-score computation\n",
    "\n",
    "        self.calculate_fid = calculate_fid and self.accelerator.is_main_process\n",
    "\n",
    "        if self.calculate_fid:\n",
    "            if not is_ddim_sampling:\n",
    "                self.accelerator.print(\n",
    "                    \"WARNING: Robust FID computation requires a lot of generated samples and can therefore be very time consuming.\"\\\n",
    "                    \"Consider using DDIM sampling to save time.\"\n",
    "                )\n",
    "            self.fid_scorer = FIDEvaluation(\n",
    "                batch_size=self.batch_size,\n",
    "                dl=self.dl,\n",
    "                sampler=self.ema.ema_model,\n",
    "                channels=self.channels,\n",
    "                accelerator=self.accelerator,\n",
    "                stats_dir=results_folder,\n",
    "                device=self.device,\n",
    "                num_fid_samples=num_fid_samples,\n",
    "                inception_block_idx=inception_block_idx\n",
    "            )\n",
    "\n",
    "        if save_best_and_latest_only:\n",
    "            assert calculate_fid, \"`calculate_fid` must be True to provide a means for model evaluation for `save_best_and_latest_only`.\"\n",
    "            self.best_fid = 1e10 # infinite\n",
    "\n",
    "        self.save_best_and_latest_only = save_best_and_latest_only\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.accelerator.device\n",
    "\n",
    "    def save(self, milestone):\n",
    "        if not self.accelerator.is_local_main_process:\n",
    "            return\n",
    "\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.accelerator.get_state_dict(self.model),\n",
    "            'opt': self.opt.state_dict(),\n",
    "            'ema': self.ema.state_dict(),\n",
    "            'scaler': self.accelerator.scaler.state_dict() if exists(self.accelerator.scaler) else None,\n",
    "            'version': __version__\n",
    "        }\n",
    "\n",
    "        torch.save(data, str(self.results_folder / f'model-{milestone}.pt'))\n",
    "\n",
    "    def load(self, milestone):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "\n",
    "        data = torch.load(str(self.results_folder / f'model-{milestone}.pt'), map_location=device)\n",
    "\n",
    "        model = self.accelerator.unwrap_model(self.model)\n",
    "        model.load_state_dict(data['model'])\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.opt.load_state_dict(data['opt'])\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema.load_state_dict(data[\"ema\"])\n",
    "\n",
    "        if 'version' in data:\n",
    "            print(f\"loading from version {data['version']}\")\n",
    "\n",
    "        if exists(self.accelerator.scaler) and exists(data['scaler']):\n",
    "            self.accelerator.scaler.load_state_dict(data['scaler'])\n",
    "\n",
    "    def train(self):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "\n",
    "        with tqdm(initial = self.step, total = self.train_num_steps, disable = not accelerator.is_main_process) as pbar:\n",
    "\n",
    "            while self.step < self.train_num_steps:\n",
    "\n",
    "                total_loss = 0.\n",
    "\n",
    "                for _ in range(self.gradient_accumulate_every):\n",
    "                    data = next(self.dl)[0].to(device)\n",
    "\n",
    "                    with self.accelerator.autocast():\n",
    "                        loss = self.model(data)\n",
    "                        loss = loss / self.gradient_accumulate_every\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                    self.accelerator.backward(loss)\n",
    "\n",
    "                pbar.set_description(f'loss: {total_loss:.4f}')\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "                accelerator.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                self.opt.step()\n",
    "                self.opt.zero_grad()\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "\n",
    "                self.step += 1\n",
    "                if accelerator.is_main_process:\n",
    "                    self.ema.update()\n",
    "\n",
    "                    if self.step != 0 and divisible_by(self.step, self.save_and_sample_every):\n",
    "                        self.ema.ema_model.eval()\n",
    "\n",
    "                        with torch.inference_mode():\n",
    "                            milestone = self.step // self.save_and_sample_every\n",
    "                            batches = num_to_groups(self.num_samples, self.batch_size)\n",
    "                            all_images_list = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))\n",
    "\n",
    "                        all_images = torch.cat(all_images_list, dim = 0)\n",
    "\n",
    "                        utils.save_image(all_images, str(self.results_folder / f'sample-{milestone}.png'), nrow = int(math.sqrt(self.num_samples)))\n",
    "\n",
    "                        # whether to calculate fid\n",
    "\n",
    "                        if self.calculate_fid:\n",
    "                            fid_score = self.fid_scorer.fid_score()\n",
    "                            accelerator.print(f'fid_score: {fid_score}')\n",
    "                        if self.save_best_and_latest_only:\n",
    "                            if self.best_fid > fid_score:\n",
    "                                self.best_fid = fid_score\n",
    "                                self.save(\"best\")\n",
    "                            self.save(\"latest\")\n",
    "                        else:\n",
    "                            self.save(milestone)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        accelerator.print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:14<00:00, 70.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Inception features for 50000 samples from the real dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]\n",
      "loss: 0.0464: 100%|█████████▉| 999/1000 [53:49<00:03,  3.23s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoaderShard' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/0225_code/git_file/denoising_diffusion_pytorch/fid_evaluation.py:63\u001b[0m, in \u001b[0;36mFIDEvaluation.load_or_precalc_dataset_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2 \u001b[38;5;241m=\u001b[39m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2\u001b[39m\u001b[38;5;124m\"\u001b[39m], ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/dataset_stats.npz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sampled_images \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39msample(batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/0225_code/git_file/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:1067\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# whether to calculate fid\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_fid:\n\u001b[0;32m-> 1067\u001b[0m     fid_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfid_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfid_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfid_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_best_and_latest_only:\n",
      "File \u001b[0;32m~/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/0225_code/git_file/denoising_diffusion_pytorch/fid_evaluation.py:94\u001b[0m, in \u001b[0;36mFIDEvaluation.fid_score\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode()\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfid_score\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_stats_loaded:\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_or_precalc_dataset_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     96\u001b[0m     batches \u001b[38;5;241m=\u001b[39m num_to_groups(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/0225_code/git_file/denoising_diffusion_pytorch/fid_evaluation.py:75\u001b[0m, in \u001b[0;36mFIDEvaluation.load_or_precalc_dataset_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_batches)):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m         real_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoaderShard' object is not an iterator"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:11<00:00, 84.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_images = diffusion.sample(batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAADeCAYAAAAJtZwyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3q0lEQVR4nO3dva4kS5eX8RWRmVW1d3efdwbNINDcEy4mJg4eEkgjIY0QHh4WDhfBGHAveICEg9DM+3G6qyozIzB2oxkjntW79hzNqRTPz8w6+R0RGdFb579K772HJEmSJEkHVX/tC5AkSZIk6e/Cha0kSZIk6dBc2EqSJEmSDs2FrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDm1+73/4X//zfxpub/9nw33K6TbeXs7D7X/4efzfR0R8u38bbr+v4/++7XioKNGH25dp/Dj6zvc4z+N9GlzXvIzvIyLiNJ2G22sdn+PldcJj9fEtRuNdokJz+N39d8PttyvcZAS2rLou8N/D9ogoUeCXNty6bnxd9328z6fzy3D7uXJDuryMb/Kf/LN/ifs8g//4H/5iuP2vb/ScI9Zt3HCWDv82dufnVpdx42xt/G4KtOWIiK2Or7lv450m6EsREZdxE4h+H/d/OPX3H8ebl0/jPr6U8faIiNNp/FxuN27n334e3/8O/Wzv43NERFB3qvCMl4kfTIE+W/t4n3vc8Vi1jF9YPY2Pta889r7AN+Ff/Plf4D6/tn/37//tcHuDdx8R0eA+6V+4K469/Mwul/F/fzpzG3/5DN++ZXxlS9L5/rDCPGIdj0lT8s/7O3wv1g3GquQ7VuGjvEM/iojYtvHYA5vTP1XscJoVHuWVpz3Rob/2FU6SjZU09MBQnTzi6H3cjv7Nv/7z5AJ+ff/lL/9yuP1///f/hvvU0/heGzSOvfP3YtvHD7Xt4/F3avwd7X18rK1fxzvwpye2Om7QUxn35XLnDtAqnAja5lSTcXQen6cnHfDn6/hZ7rQeuXCn+Qzz1ellPE/rhR9yXcbP8mUbr9P6C7ej9T6+x2/X8btfYc4VEfGyvA63//N/+q94p+/8i60kSZIk6dBc2EqSJEmSDs2FrSRJkiTp0FzYSpIkSZIO7d3hUdu3vxpuv3dOGDhB4ExAGMqWHItCHHYInInC/+N1g/8nfKp0fv4fr3f6n7LhWNuepDfBsaYy/p+1y5r9D+HwbxaUKhURHf7n+k6pE8kzLnCeOlMSTdIU6X/un+BZVv6f2wuEV52XceLJGdpqRMS0ZIkYz+vr1/H2LQkxaRTURZ0Jwh0iIupObRN2SB4zhqTRuSlAIiIaBKI0uAAK4sn0K+xz5jZLQXQ3CMOJiLjBe2k3CLBJAjw6hd7APtlz6fgyKVCMr2ta4MHs47FkzUJ6ksCrpwXhJtnzpyGbujF3ygjI6YkK4T7TnIylZTyWF7jgnnx7phgfa4VPTBZOt8NpKIylZ6GVEHh1bzzvoUw3Og2/xzy/aST7q8eGH+XHx0QEh9qSZzzDXOnZ3X77P4bbf//1Z9ynXMchaR3m0ds9+b7XcbAehZQl3S8CvqMrfEeSKWlQNiXOopNj0RBPzek0Z3N1uLDC81jq5x0GoGlLgrDO44HhBM8++fTFDGuSfR4/mfOedEAK8zyNPwo9mcOU149/k/2LrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDu3d5X76t3GMets5qp5i2QtFUm8c1U6/NSprkZSJoBICK5UhSZwhLHyD3HGo0PB2XRShDzfTKAs9guPIs/INUHKhV9rOx6pQDqFBUHtNygRQe6Gg9p6UVNqhEMwVjrUkXaRw039qDe6pRHJD8FOHR531Pyr5QrH/aWUB6P/UmrbswlZqN+OjJRWN8AI6lRzJ+iVcchbhv2FpBSjdkz7kx+owcUkffpf0VrDrJwrUXOlQiiAiYv8ly5T8PfnyedyYNqoPFYFtnO6/JqXuXufxN+bT67i0w+nyise6fH4Zbp/m8T0uSdmu6TYu3bZCfaqkqEd0GC9WmPfU5G8F9Mtl5XF3hd+orM+WzMc6zBdorpJVO6G5Ej2Xloy7WIIN5mktmfZMp+xtPq8bjLEtmWNND47x2Z+xqG1MVAsrGZcbzD1nKBvZJ24bHY5V8duTzCPhAUxU5nJK5n7wLcE5fERMMF5i1c6snORM7xiuiyYRwc+swnqgJZMFKgu5wYBF1VIjIk5Z7bIf8C+2kiRJkqRDc2ErSZIkSTo0F7aSJEmSpENzYStJkiRJOjQXtpIkSZKkQ3t3KnJZKYaPY612iI0tbZyqtd850a/BebYPJNN2SHprkByWpp9ColuH681SPnd4LhOklvXGFzatkAw6JYmlkED37XYfbl+Td09nKRCDRsl0EREd/v2FjrUnCYwbtGMKH7y2Ex5rz1Kpnxi1G0oajAh8oZRYnYXZVkzZBcl/Tgm81AImTAuPmCFRkBIjsyRv+ifDCc6RpqlWSqzk008w9jZKOkzSCQPGS0xTzF7YY6dIj4S/0c1AKmdERPtI/PKvrNzoB96HUrkhFB6Tad8O9li6eYe06oiIBonFFRrGmiTfb1COgU6/J2nZffzpi0bRvMmxEHz3334b32ehttySJFcaMOCFTUnAMH+Tx9vp/UZE9DYeqxZIhc2mY0tWduKJ7dfxc+tJwDmF035g+Isd3g/tkzXzQpVC6PzJC+3wJcec/jStGb5jcJM1+OEX+I6mXyyYL1O6dUmqtFSIUq4zPK9k7KV5zwwNidZPERE0JZqgfWXjwvR3qDpyzJm5JEmSJEnfubCVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSob07FRlj0LKUXVo30+Ykau3R02dBg/QTPYwkSDUoG40S67LQPkpHo+dSk1ReSodLAs34vVAyXppWC/DC+F4o5W+mfSDdOoNJb8mhpiyW9on1GZIrKfk8Igolc1OiX3L+QumEH0rGpcTesZYls8JV0zmytkH33yHGvWPKIqe1tyQVvUGnaZhYy0+ZuxOlteOhsP9TYmX2jKnBUPvKTJA8/czWddyWfoYk3whOy6d2kQ1xFdKHZ0zR5jbeKyS1w0dmqnys632cZrrvcI4s+Bn2oeTlmkQJF2jM+5378Q7va4MXlo0JAW18hQ67UfJzRGyQJNupf8NzjODxlXbJhoS2JlHOT4wCYLdkXoRzT9hOfTyC56v0WciORZUK6D2XdLbw2FieFVwoj85VksReLhPB7bxALDSe/54kiS8wxkFDouTxiCQt/gQrop0/MJQwv0OKc9omYex7j+N9zSVJkiRJ+ltc2EqSJEmSDs2FrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7t3eV+rlCm4p6UFijTOOK5QJmaFeKwIyKukPwMqftpSDhVnKHo6Zqkfnc6FiVV57VLxueHXPcpKWvR18fLM1GOfqdo/ySNm55LgYecvq9HS5Qk11Xownb4Nx5owxERneoQPTso+1Dn7IWO9ynQmXpSb4tKq3ToNGngP50f3nNSjSOWGX6Ehp4VKaDqMXVehttPp6R0Fz2v5N8l6fnv8B6ToRfHBS6fkJSNgnIANPZS2aKIiOk0fpYVBoxSueTB5fL+ynfPYqcxKyn5Qm+Gy2MlF0BDKbbLx8v5FSp3kpVBoTEBTkL/fUTyXKBZ1uS6Kt1/UjevQ7Oc4Juc11mj6xqPezV5LpVK9NBlpTWVaDuUP+QjRcnKHT0xGrOy7yi150f7eERSnu7RHbJjYUW3rMwgbH/4grlv7vCBw7EnIgrOo5NyX2W8WKJ7qVCWMSJimsYDw1LH21vSl6dp/NBmmHe0pDRhgfufZxgwk+46LePv+3v4F1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhvTsKskH68T2JTcRVM/xwTxLN1gdTkSkwMjl9TJBAR0m+ERE7hI1xml2SgAiJpRUiSyl5Nf8tSTqEpDdK3+w7R5rh7VM6Ij3IiGgUi9wgtY3i94KTdxucvycNqVHC8pM793E67DVJruwQhFc4txCPRWGDHX7IAjX3B98BJUm+nR+jWcebs/M8+Fjw3JE8L0gzfDveY9mYPc+ehkNRBGpyXfAAKE21JdHrtY0bJY0XvXPC8rodL+G8Uip18l3AofFDtw9J6fTxSS6sQ9ImHisbFKiMALTx9HsB22lK0NMYaUgS3vnh7+v4t52OlaUCY4I9jQnJNxkumRJuswoC9MQ+MIXJhp6nVus4AXaipP6IoAdRaFqfjcvwweqQ2J0lBnOnoctKXhpGBlM1BG5nWZrv8L9PKohUGJfS54KrLUhlTko4lPk0vi6ouhA7l6+heT8lmZcVD4VVVwrFuydtct4/XqnAv9hKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDs2FrSRJkiTp0FzYSpIkSZIO7d2xUyslc0IybUQkcZ7w32OULqeGNkhty0I+H006zFf/kM6G6aMM0xkh/XRPklQ5OTBLDB5v3yHRkJJMs98oAW9KYjk54ZVSnDkZch0HAsc8jffZ4L+PiHgsY+953OCe1iS5kh5pgUbTk6RD6uZ09iw08dFgagxMjYgCPZ2SFrNxgQIYd+qYycEmuMkNElMjIlZ4YfSKt+whQ2fG4OcsKX+GJHO4sCxklsYl/O+TAatOx0tFvhYYl5Ng3Mh+G8ieygZpvjTG1uzcUN6gwmAxJf3lCiUUNmgvlC4dEdEgZXiDD0NNUlEnTEVOvldwftqjJenelOR6h/FthyoNERHro+naWUOCY210+uRY2fj+zGh+vWVTPBgcN3if2XBJ4z/NCQvNuxN0rPRIeC/wrU4aR8H5Ms1hssnC49UFVhiXGpw/+yat9/G1TdDHW+OJLM97xtt3qKrx9uN4Hxovt+QDf9uT8/yAf7GVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhvbvcz3Ia/6cTlG+IiJin03A7lejYknV2g1oB8w5lgJII/wpR3RSHn5UDmCHen8pX9CTeeoFnOUG5n2Xm11fPy3B7Vh0FqzMVKDkA5R4iuNxPhcj1Oo2vNyKiwT4LRKtvOx+rwjWfLpfh9vOJn9ilvrv7PJUZ2k1W7meClkMlB7LY/VrhmT5euSsvFTBAZXgiAmuIQFWV9OxUWQBLDiSluzqNizUpkYUXRjs8XjqMxrKejTJwnkbnT15wg7G/UCmGpNxFS0qbPKtK5ShgvH7bCbZTWY/sAqbxOFLm8XXR9oiIE8wVYhrvQ9/qiIgF2mWBEiE0H4iI6PAtqWUdnwOPFDFDiZQtqVHT64MlL0pS1gMe2QTPC/tkcOmmhoNl0pHh+WM5seQhZyUIn1mt9+H2BeZ+EZE0Nhhj0xqYUPKF+kb2uYB20+FesnGZjlWxzCdfGFbign1mmqdEBC17uDRlRINpKa1V5qShLxPMiaFEEJUUiuD7pGdMJTsjuNzRBNebtcma1ofLHe9rLkmSJEnS3+LCVpIkSZJ0aC5sJUmSJEmH5sJWkiRJknRoLmwlSZIkSYf27ljXbR8nVG0bp/C1BulolIp8HycNRkTc73D+D6RpUppohZTNmiRmNkghpNP3JHm2Q2wbBJ2lCWyVHmWS9EZhmvftA+8ew1/H95g1xA7Pf4cExn3jZ0wJdFsb38u6c2JlbeMkw2d3v4/vNUuUxGabpHwTShmnsL1fMuiSUhYjInY4U6HtWTogBvpBAmn28CE2Mt0H3he9x+RW+B3DTmmSLl5AthPt8ss1mJpFcz6p0iGVmD4Y8Xi7TM9PYzz89+m/okMCJ6XoT0liKH3iZrjHnowJ9FQKpcQnN0n3UrIkY3rGlPycdr7H5mMpuM9C6bpZ/6LvwUeu6yP7PIFzGUfmLtkLhZ8g3D/W7FAwLtA7SJPE6buA81i+LurMhRJ7k/lIgXk/XS8l+UYk7yVLRYbRhIbkKTnWNI3HDEpS7ngWbi90+7BMekNtEl9+UnEmnZTk/IutJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDs2FrSRJkiTp0N6diryv41StNYnIotRKSiHbk0SzDfcZ//dZWCuGjUHS2sRRko8GhuK9R0Q0SPOtEMy7J89+quNr7sk+lDR3g/TjlcMckzTJ8T1uCz+XHRLdKK+4QYJ3RMROCYz3ccLx3k94rI2S3p5cx+jIJFGQ0vbwUL9klnHm8Xth8D5hwMiCPuuj/2SYXS7+liRT4g8fSBLG9OPHnz03i8ff18NNLPnvkyD1p3Wu47EpvZUzPARI2M6a8eV8Hp/iMk54fX258GW9fBpuL/N4ijLRRzEidthnb+NSAVmSaoNOvt4prRkPhd+rtL9AXC3NYerGF9AosZjmaVlDomZE87HkfXV4LxUScbM5FCW8Pru2w2Qqm3vCXG6ntPyknXc6D3zgk0IhODA3OH86jsO8gyorpKhtwn9ek6oDDVORk/UQVTfA15W8L5yqjN8jtongJsbjAg8MNE+k78ueRWJ/oOLG/3PQYUCSJEmSpDcubCVJkiRJh+bCVpIkSZJ0aC5sJUmSJEmH5sJWkiRJknRoLmwlSZIkSYf27nI/6zqOXk4qvmD0NMW1ry0p00Jx0RjhndX7eWhz9CySmvaB8ydJ2ZjhX9v4/AW2v51o/Fvj1H08zwb3n8WR020maeh8LDhYh/JE1CYiuDwNteMpKZ5xh1IMz26CtrlBeYWIiN7G/wZWoBRTSY5FJTHoSWf9j/p5gfISWTmIGWr0UImqMiXlkWA0qXCOaeKOOcGz3JPBhMqhFPi3zKy0R8/GmfEe+EuF++ww9mfvvtZxWZmAMlxpVYkD1gl5/ePfDLeftm+4T6OBjsr9JI/lp0/jcj+vr+P38vn1Mx7r8mVc7qcu42PVCd59RLxer8PtVLonaxcN+ti2jkvUzEkJuAke5nYbHysi4go19TYohbFBab434/Pf4Tt+T/reCs+FSrrs2dwOyv3QG+ZydVyy8NltG5TT3LIyLTDHhAlQcqjYYYyneSyXekt8oNIc/VigbZasZCFMPLB8VNL+6f6ztkk9k0aMbKnQoC9vffx9Tar9xETvvozPQW0lgud9K50jaZT7+oE29t3xvuaSJEmSJP0tLmwlSZIkSYfmwlaSJEmSdGgubCVJkiRJh+bCVpIkSZJ0aO9ORZ4pUSxZG88z/AZBWNOUJArCbx1SuNI8LfoRtlNacASnRlJi8Q7JxxEREzzjCtunhZNU52X8arOAZ0osnrdxPmFJMrEbHQy2T3C9EREVUuvwNSb/XAOhjXG6jM9/glTOiIhTkvz7zO6QRLcniZIF3gEnCvL5Mf0Ytz+edNkhGTIbrzo05w5ttiRRwhUaIYampkneDw5YkT3+x9tswbToR8/NzwXHxSRGHZO3C4yLSYr7Hklc/JNalgv8kqTVV+gXkHI7J4Pp6TxORabt59cXPNYL/IapyPSOI4I60w79ldp3RETb78Ptd3iOlEYewZMtSl2PiNhowKBXnD0W+Pjv8FGck47cobwCJrVnyer7OBF4msdPrCXPK60U8cT26wdSkalaBQRQZzUcaCaH395kLP3A5zrxWCpz+u2BaGDah8aLiIgGc/Jkeh93eAE0J8UE+4i43sc/0lC2r8nbf/D7viVlRyZ4xrf741Vipi3Lhc75F1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhvTsV+eUTpBM2XhufIdGQUvhekqS1DimE60bpaB+IZoMEzpoca6boMEjna0nS2gyJipT+uUBqYETEcho/+yxnrEAC477DdWVBh3iO8U7zzHGO7cFkvto5yXiHJzCdxs+ywvaI/P6fGjzrOY0yHu/TyjidL3s0FdozdY2sL1OiIEVjlyQWnH7hES67S0hzhPNnaYqUmoqJ1MHPjBJF02NBdCH15exYex8/zd5pxMgSax/MZYb01YiIUrLM0OfUIMs0S/Okd9MggpP66tt5xuMsvcvWVjzWBunDE3yT2sTfi3W7Drfzc0nSxffxNd/X8TlmjD3nSgH37Yb7rJB+ukH66JbFjMJ9bjBXoRTXiIgdxrEV330yJrTx/XeYW2bfA0xlfnK9wJylJlN0mhZhdYPk20djNsXsZhUUcPI33vyRgOUC50//Ukch+lSlJRn7Kkz8sxlBgT5A589e/XSi6iJwBUm3qAs8tWm8vSbR67RWmXaIeE6uK1sT/Ih/sZUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG9u9zP/QqlBSgOPCLWQnHNEFW/QiR0ROzreJ8OUfVpsR+I3U9C//lYFHsOcfg9ib3nCPVHt0f0BpnrSR55p9xxKJPQk7ISfA56X0mJCrjPDjeTXRfdI+6TvK7tmJUF4st5fOG3/YT7FHgQVL6lwPaIiBl+6tRn0ncAJbpgXJom7gAniKqney9ZjR5om8syHnLnMw/FdYLSBknJkwL/ZkklNLK23Hb48QPlfmYow7TBeNWTdlSp3BmcfkvK/cynj5cW+LVsUIpma+PSORERHZ5BgTIpUFXm+/nH74ZKruw7t/HWxuVOqHRIwfJQEQXaUqHvWDKHoVocFbZD846IiAn2ycuKwLFgrtCzFwZj0gSdn6737USPvftes9pB8L5gn6xk29a/8Xme2FbGfTktnQbtvME+OL+LpOoKlafLvhdYh4jOwcfibwzV7nn4UDi/zPpygROl/Z+GP3iWFcrtRERUKIVDc4KezBVorkSDT5/45VO5n0LzMSjjGhFRsJbqj/kXW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG9PxUZksvuK6da7RT3Baltt+RYN0hFhhC+aElyHiXzFkxLTlI+KVENdqHrjYjYIdGQktayJNMZj5UkKcMzu93GiX335AIeTa3bd35f1I7oTigtMCKiYMogJAlu/Lxqkuj2zHodJ+RNSdRhgQRUaudZYjAGE8P2rM/gTnD+JYlNnLFvPD4u0D4VUgPnJK15gkTBDdKSIyIm+I1TyVmlf//ExEp+YROlNm50/5zmOFEqMtxNljKJAf5PDPtF9jJpbKRE8iwZl94/jeVJP8aQ4w8kbzdISsdzp8eiD/mDya8RscOHvHMxCP7+0HmyqguU5IxzGD5WgZdJ4342VlYYd6m70hgWEXFKUtSfGfazxwO7qStTcYsfoIoUiV9yWoT3SN+35FgPjgtJjje35+TBUNEX6madqhFExArjwjqP99mScYEqtfQyvuCeTMhornCDfdIiMUkVgx855iggSZIkSdJ3LmwlSZIkSYfmwlaSJEmSdGgubCVJkiRJh+bCVpIkSZJ0aO9ORf797bFk2oiIVsapVpTCdUsSaG8QkMWpWsmVJWl/j6J8MMpfywLjGtw/pTX3JLetQ8wnJlUHp+zd4bogLPn7tT2Wprck19UePBYmWUbgP+UUSN3OEjPrx2IGf3XtOk6725K0yQItmpL7svzBAsnAlICavc6O7Yb+zS45GBwKH0tyk3T2SsnTWVuCqMeCUbL8G40l6XBJqan4AB4fezlpMUlep0cJ+zRIin/b53iWGZ5/5c96o9RaeC+UWBsRMc/LePvpPNw+nU54rGWBfWbYJ+l7M6QyN9hpyr49ZXyPBRJWqUrC22+QlJ4kcu+Qlr7B+6K04ojAOHrq39sH/uwxQ5Ipj9McVsvVK5Jv8vh1Pb9p3GeTsPwISICuMC/s9N2NiA4vIU0ZJjRm4HidwOjnRy7o+6GyhPdH//sPTC/wWX5gfoHPGKshZOMC/AbtpSfVGBq0PQrKT9ePUA3iPfyLrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDu3d5X4K5I63pBxKgRx7KlOTxZFT8jOWdvlITjmdJC0PBGWQ4PxUuiYiohWIb4db2YPrBFT4N4usfA3FizeIle9JuZFH09gp2v/tPHQO+CE5Fr9LiDZP/uln/1AW/q+P3lpSDSUKtedHS+QEt0EqOZKV+4FqQ/ieSxJVT2XIOPY/rZEzNEOfPfVkKIY2eLuNyza9/QZjLFzX+oHSXThgJGPMBN+RlRpf0o6mNr5/KkG1Nx6vpqTkyrOivrdDyZWIiE41kqhsV1YdC87T4L00LOnE11yoZGAy9m5wL432SW5yg1J3+x2++0l5pB0+5Bu/LiyBuMOzpO0REX0fDyR3uIBbMvB2mNvdqO8lH5cVztMqfVzwUBHtmH+rmegZJPs0mnvSDkmfKQ+O8fzfJ2XgoJ91mPdmv1FJo6xCTJkeq9FzmvlgJygrlc1jK/QzqnK6cHW0+PRpfAGfLuNrvk18sNMZSppBH9+pdk/wvK9U+FYkz+vl9eMf5WOOApIkSZIkfefCVpIkSZJ0aC5sJUmSJEmH5sJWkiRJknRoLmwlSZIkSYf27lRkSj9uWfopJBpGgay3JE0Tf+IIODwWwhTAJMkYtlfYJwv0o1RYuvmapDliOlzywiigjI6FIXORPEoIOqtZKjKG2T2e2EfvcoIEvCxlbznovwvdIQE3CbsLaukUwpk+Ger+8J9nbxPDdCH9NbtH6k8c1p70P9oDU5zxUNiZsmeM6YRwLAgrzk4fFGaZBa9TziEFw9ZkxOT0TRgXkvTNPU2+f051eTzlt1JaOPz3U1KpYILZA+2TvUs6TaGU4ceHeEx271kbww77eNUBTJZPzt/pPBRIjkcK7BcdI8GzdG1Kqx0fCxOOI6J0OD+242TaerxuHBERp2X8DC5nToZd4fms98erRTRIk+74YUjGGJgUJKH06Jcclmk50qmdZesR+igmqehYwAUmMUnRkQhInqe+VNsdD1WpuMI8fo9152oMNPYXaBNJkYqoha/5R445M5ckSZIk6TsXtpIkSZKkQ3NhK0mSJEk6NBe2kiRJkqRDc2ErSZIkSTo0F7aSJEmSpEN7d7mfAgnP5d1H+BsUiZ+WwqFyAHSOh67oRx4v60HXld4jlgiibP/kLrFKAsfu4z5Q8oBKvURwGSSqIJCVA+hQHqpT+QYs0RD4wnauG4OHKu/vPk+lQAUBLiwQUaBM1AaNJvsXM6wg8oESFnRdBQaMhW4+ImZoZxOWj3l8lFmgftRck6cP54EKDd+PB+WOqERW0mWoDBmNS/k4/pESXWNUUo1aTEvOkVa6elKn03j8afWE+xQo30GlMKakDtTp5WW4/XwZn//l9YLHev08PtY0w70kpTAKTEoajEpZ22vreOJzh1JLU1JSaoGflo3f11xvw+0bdNg9+ShXuLbrNr7/eU/K/ZRluH1t41pyd6z/FzGv1/F2+Lz29vhY+ez2ffzcOpR1eduHJlPjzR96MlAfLxsvseQVlo1LyurATlRuZ0q+Y1HHz4uaTE3mkXTJ2Zx4gudCjyubXdJvVD5nTiYLM5TuKrDPlszuqJwcVNPksqARMVNNs3fwL7aSJEmSpENzYStJkiRJOjQXtpIkSZKkQ3NhK0mSJEk6NBe2kiRJkqRDe3esK6V9ZSlglFr7ofjTR6WxbbDLB8KHH43TzEL7ksDWseSfJSiccYIEtLedxptniDTbktRETEyFlM154abYKBX2A+l/lGR7Oo1THmPi5zVBwu2zo1TitC//guenPoDDBSQfvx2LDjZ+N2lfRhgXnuwDSd6QNEgpjxGBkbUt6X8NXiZdcppwTr/Bi8xCySkxk0PJk8Raemb7+AK25FhHTEWeXsdj5nJLPiQQsjrBSy7JGLcs4/MskNZ8WmCMjYgzROAusM+eDL07pPx2eMu0PYL7ywQXsCQJrzMlomeR5PAqV+rfybF2TIqHPplUKmjQkDpGzOKhMMp1ofdF0a8R0bLB54m9vIxf9Lpxn6HHsM0w90pTZscvqGFFgCQxGNomvZueVQSg6+rj9jcl8zWuYjDefj4lYx9NV5MJ/rf7ePsGz+V84vf1chm3i0+X8T63JEn8chnfzD6N9zlBUnZE4P3vkO6dDJfx+nrmH3/gmDNzSZIkSZK+c2ErSZIkSTo0F7aSJEmSpENzYStJkiRJOjQXtpIkSZKkQ3t3KvLpNE7I2pN0tBlSEwukaq1zkvJJkcVw/pat2SmBkxIgs9BCuiw4ScuSOSG4jJLDKp08+Q0CQ7/vBNspsjT7ZxFILKX0156kGTZKmIXUxNa4HUHQW7S+jv/7NPj246ltv6YNklE5NTA+Gic8RGG2PJTwuXdoA9MHEnspfbtAjHT6vMAOF1CTe8SxJAknpN/o9rNQZtqnYspmcjAcYynlNRnj4Fgdxit6jhER7RfN/f77MUOSatuyzzqkH0ODmZNvzAnS8inh+CVJGf0EMaMnSFhuyYestnFiaKGE1eQD3yAZuJXTcPs5ifmcIP31moXCPji/6ZAWGxHRYZ/rNj7HqXM76m382w2+vVki+W0dX9cJEm5LUtlhW4+ZivzlddyeKOE7ImKB0hd3SgXPPhj0E3z7pnR+TYn8sD1JMqY2S+n6E4xJEUmSM3zHL7B+iYhYxq8rkqlnTMv4PND9Yl74ff30Or62L7D9WnlceIFU5FbH42iDhOMInitN0/jBlODU79dPr/jbj/gXW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHdq7y/18/vJpuP2+c771p9fLcPsO5RgaZo5HTONqLDHBsagUzNuP498qxI73JMN7gajwmcptJMeaZyiPRP/9iaOyT5dxKZrWkzxyONHtPr6u8+mOh4LqHRFwj/MM+ekRsVM5Bigb1YKPVWN8/y+fxs+rFu4ideHn/9TgPVObjUgKuFDpnuT0lO4PSfF5IRZqZ1AmZkrKlyxQPoYq1BQotxDB5XuoBNq8ZGUK6AK4L9Mza/Dwa1by5NHyaElpDyp5Usq4hEAJLrkwQ//b4LlAxYGI4LIuz+yPX8dj1tfk+fc7vH8oE3OCkg8REV/g/L/59DLe/pnLN/z0Zfzb6TSeQ2RlXZZ5/F1qMN0p+LGK2Fb4xkEpjqTaSCzQ95LPaMzQL3cqQ5SUz+gwjpzu445xSuZ2O5znso/b0ZbUWfsK/fUCH6Rs3A0YX57dVqgRXHGfDiUK+wdKl3WYE1NppbQ8GswxsdRlUr4Jy3zCOQqWoOPSnFQ6KPu+UlWvrDwdTYoK9PGs1Nq8jK9thu5/WmABFREzlFqb4Cb3rDYg1MfcocZktk670KLvHfyLrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dDenYr8J3/8m+H2DVJmIyK+QNIhpWr97vecZvsNArLWbZwo1kuSjgcBfRUSe6ckHXCCVGRKfm1JAiOlshaIiz1d+HldLvDsk1RkCnS738eJfdcrxzlSCmKp42teIMU5gtsLZrMlydOUZvfpMk7frJ+ShOUkyfmZvULXKGmi5PjBbdCes1TkBdoztb+WpPBV2gk2nyHNNCJioiRj+O9LkqRb4FgVkhaXZLyilMsp6cv0GyW8lyRJl5ImK7wXSnnMzlMbpCJThw1O7MTnkiSzUiroM3uFsXRL0iTbNH4GFaoLUIp3RMQCv51O4x5zuXBi72UZ38sJkv83+O5G8HjR+vhYPWmvM44vkLydXNcM42tL5lDbndJEoX8nSa4rJBk3GOC2JOF1grRyepYdKhhE8LxngvlYbUlfrUn0+RP7zafx/GNKxqwbRHDfNmgbSfow/o0L2nM2WhZom22HtjHxGNPgu9ghfXtJSjvQN7nDd/xy4es6wU8d7jGCK7jcYcg4n3gsOZ/Hv9E0+pR8308ztBfYvsGaK4LXKju01eSyMPn5PfyLrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dDenYr8j//sH41/KJzA+NPnT+MfIAnrr377BzzWHyA67LZByiYkIEZENEo/paizJMn4TOm/EySwJQnLpwleB6Uiv4yT9CIiXl4+D7dvSWobhSDe7rfh9q9fr3gsCk6r8/i9LOcXPBYlSdNr6Y3bJAQwxk9fxuefkutaFk5yfmYzRHbXLDX2wfRhjqzmQadCAmMW5rhR0iFc15ykli5wjxgMC/3y7SdIMoZU5vOJj0VXnA3elGS8w73ckpjLBimk1Jfo3BERBZ4LhR/XJBV5nin9lhK88VCxJed5VvT8s3ZZHnxndUqSceECKFy9Jumnhc4DfbIm6bcVklQLnL8k7aLRQ17G37EpS1iGxNY5OF1/Po3TXxsMvFnyLVWKoFTWKcbnjohohe4fzp28r6nBe8GGhIeKeXv3lPapXCCZl5KPIyJ2+JZQ26BxPCIZy6H/JYHZEW18MNicjledyovs4+00t4mImGCMp8fyeuZjnaEv78kzniEZfIUU/0uSivybl/GY8eV13C/3aTyHj4g4QSJ9mcd96XbPxnH6gRKW+Rl/On+8UoF/sZUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG9Oxv9C1TPaYWj6l9fIHoaIulf7nc81gZx0RgVXvnWKN6/niGreufY7RPE2OO/GCQlVRaIKi9Qo+F04XI/l5dxmZo9KfeDVTrg/EnlopgalPWgcj/JvdAld4hJbxvHkUOCeVxexqWpypnb93Qal1R6dlQIK6l6ER36AJd24T6D/Q9qCFD5loiIyo12uHXG+kQRE1xzfXB7en4qa5Mk23e4/6wUToXyEY3KuvDpI6hED9wjlTp6O9Z4H6z2klwYlW/o0P2npB1FUormWX27jsux3Dcud9bv431qh7IyyQu4ruM29u0+Hpevyff9NI/H/w7XtW5ciuZ6gw8TlRODb1VERFvHz7Lv4/IZJ+h3ERH7Om7kVyinFxFx/TYuqdehFM+enL/BdO8GbQKa19uxoJzhHd7LmpRMvN7Gz3jO6nORj+zzBL5evw23376Ot0dE3OAFwePMqlZGhdJKBb5xJfn2dJiw4dQ3qR3UoQRm38c3uWANNP5edvperfxNoKpSDeakEREwXOL2lpQA/Pk8HjPKDmPszqU5V5iUlGk8U9yS8ZKqjd2uX8fHwvpAEXHlufeP+BdbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSob07Ffnafjfcvu+UsRqx3CBNF/JXv97HyVkREdf7OInrtkGiV3JrlOlVY5zCVTZOOuuQDkiJoT1JRd4gFZkSU1uSAFem8b20JMmY/pnjvkLSIaQpRkTslL5KCatJWnODFLYdtmcplxBiHStsn6B9RURUSup+ciskR2Z5khQcSCGAWV5wo0RF2JwFXfb0qgfHSv4pr9D7hOvKwn+pLzVIeaUk3+wC1iSW/A7JmBukWyeBtUHdiZ5X/q+l431giIlpTlLcYSztMF5vWUNK0mSfVZ3G9zknScadvjH7uAHOSXWBeR5/Y2b49szTOKk/O9Y0n4fb98bzjuk0fi4TJHDStyoiotN3HJJEKVk9ImKaoboBRYlGxArFAlqBJOVsTApKvh2/42niPlEgRZfmPVOWRg+TklLH73hOUnSng36TKX37BgnjERH3dfyyKTA8Cbnmd0DztWy4hBNR08RU4uCKAPAZjZKsaMr+WAWHLWn/MO3Hb2UEpx/fqUpEkjx9g/e1QJJzNu+f4DtaoH1lyc8d1iSUoJ9VvGhzUiriB/yLrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dDenYrc2ziGjBJrIyLaDlGbtJymqLOI6A1SdiEVNU0MxsTe8bEmikBLzl8pyjgJ+oLASnxcUxYaBvdIKXcRERRQVuiik38WofBnSrlrWVo0/ISpyEmScUAC5R32qUnM5F4hevbJFUhNnZJk3gb9r0A8IvXXCHwFUShhPEnO2+Fg1GbrksUPQ6IndDS694iIBv1sXiCBdBmnwn4/2nDrThHfETHTWArpty1Jl24wlkyYsppFZsL7quPrLUmjPEOS7g5pwRWSbN+u6uMJjL+Wto/bUkvSnzskadP4y0miERSKTwmce+ProoDvDmPVDuneEZx+3SAVuSVJuju1izukJWdjKIxVkG/8dhpKZYZ3n7yu2GBO1OCaW9InOvT9BmN4yeKaaa4G4y4lVUdE9Owj9sTund7nFffZ4BtLs5Kk8ER0mK9WeDc96csUMk5TvAJtKSKiwxIF08qThHFsg9Rmk/TtgN968k2mkOMJ9qlJW65lnDCPa5U6TpePiFgg+b7R9z37vEOfXSBFvcA4FhFxymK8f8C/2EqSJEmSDs2FrSRJkiTp0FzYSpIkSZIOzYWtJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dDeXe7ncr4Mt/d9wX1Op/FvHUphLCcueXHZxpHYN8q3hzIBEUn5Cog2n5J4+RnuhUte8LGo3BCllPcsQh/KfWxZKRywbuMA+fXO0eYbxMFXePZbEpNOlR2orEVbkzIoUFakQ9urd+4iC1SzenbL59fh9jrxvVI5GIrwT6oBBFXcoXT7pLJH7I3K/YzRmBQRMUHbOEGEfU1KZ9HzWpbx+bProvFy2jkPv13Hv9UNShfNSSkWGi+h5EFWhowqN9V1fL1zVu4HnhmVoNuzsS8p3fSsrvCJuyX3MmGbhVJ3M7/MDV7NHUo7bMk3ma55gm9iVglig3+vx/6alCzcOnxLqHZHUupqh/nFlnzHN6iDtFOZw6w0GjzLFcaRNRt44X3tUOtpS8bKDa556uN5B5UaiuBSN8/u9Tefh9vX5JtcZugFUD9qT8rXUNfEEpRZ6SAYZxtMCjqU4Xq7rvEYv63jN11h7ImIKNCeCu2z8Hg1LTRXT/o/9IEKpVSToTemCdZKUO5nodpsEXGax6WAahk/+73yxLfD2LtBSbVeeM1Hbe89/IutJEmSJOnQXNhKkiRJkg7Nha0kSZIk6dBc2EqSJEmSDs2FrSRJkiTp0N6dirxAOOAdUrgiIjqk3TWIVOtJMm6D1M6+js/RMbUQQ4b5hyTRDwJDo0AuKyXGve0E+1AyXZKASDF3cxJnR79UOBaEPEZExEQxexCJu2QJdG28T6vj57VDum1ExAme8ct5nBQcp3EaeETENHOi2zObTuMUvD1Jm6TOQW0TO0ZEwOuMiWLwktRSvgA4xzlJ4YPUUArmrUkCYoFjzafxkDt/IBW5Q5piBCeKUmRxS8ZLSjKfMWWTj4Xj4jS+3rkmqeRnSEWGMRaTLCOiQmrjM7t9++1w+7evSbvcxpGpHBgMEasRMcP49w0SO7++cGYtpc/PMCasd77H+40SnsfnaFBxISJi3yBdHJKE92QOM0PC8X3n53KHPt6g6sGeft/hewkZ02tWwQH6+PqBtGZMfobxZU7G3Z5Uanhmn798GW7f6/hbHRFxWsZ9c7lCKnzyd6wKk7k6jz9+WUWAAlUpKK2+JMuQMsEYD338klV2gITzCcb+yyvPFV5O4+dF/TKCK5LcYSz59MLn/9M//Wm4/TNNV9dveKwFxvEO774k42VAwvTP63W4ve085zQVWZIkSZL0/y0XtpIkSZKkQ3NhK0mSJEk6NBe2kiRJkqRDc2ErSZIkSTq0d6ci7zOkgBVO2+oVEs3qOAUwS+YMSBvbIOUzCqeTdUjanCDRsGFecESBdLhC98JBg1EoIIxSiZMEuAoH64XTVye4lw3iyZaJ09EKpeLWcWzbNHH6H72vgETsCdpqRESFiNvl8jLcPkOCcERE+Zy8zCe2QdLnyk0joo2f6Qbbk2DcoCdaIJkxS2vulIoM598jSUWmRFN6zUmIdKWEZUhFztKaA1JLMV46Imb4N8sCAax7knK5P/iM5yyRvo0fZsHo96SPwfelnCDJlgN+Y0/Sl59V38bXvFMidkTMkCZMCbjzwu/yfodk3Pv4/Pc7f5NXeGf05b3D2B8RcVvHx5oogRPSUiMi9m+UIj2+R0pYjYhYIfl/vf0B97ndx+ffIK16TwPkxz9+hfdy3XneE9BfrtAmWvBz+XaFZwx9Pwl+jgrftmf3Aum/14X7cluhz8KnJClgQgU54gT9P01FhrGktPGLgyDdiODiCus8/uGSTclgTrz08fafPvE3+fQyfl8dxp6IiG0d3/9XaNBfkkoJ/+CP/mi8zwX6343nsfMMv8FcJbakA0JDOsE3oQTfY03WFz/iX2wlSZIkSYfmwlaSJEmSdGgubCVJkiRJh+bCVpIkSZJ0aC5sJUmSJEmH5sJWkiRJknRo765xMLVxWZ91H5dJiYgo8NMEpR2WJEL8BlH58zaO6i5QoiYiokG+eIV9avKYTjGOsZ4hwnvfOY/8ZboPt1/bOHZ8SrL9O0T1ty0rnwGlIG7jCPNbUr5hg9ICMyR41+y6oFTADuUAyi0pz9Qhch7KJ2TlmT7VP+Efn9j5j8YdszeOXqfqWR1KDtSWlIKCSHgq09SoFExElA1KPsEuWIYrIjrUrykd9qHtEbHvUJ4M+v+8J2UdoOjJ1rh+zQpjA/X/FUoRRERscP6pjcfFLav1BP3vvo7Hvqyk2QznaQ2e/cbPeEpKvjyr//m/fjvcPt25BN+6/zzcvkN7uVw+47E+v4yf5/Xn8fiy79xev/12vE+B97/feWC+XaG0xMv4O0p9NSKi3sbXXPfxMy5JiY5Py7iNXZP3db1fh9s7lftJ/lTR4Xt5hxIlNyrlFhExj+dQDeYdO4wVERHb13GbrAvM07JqIy0Ze57Ypz8bt5v9r3l+ffr9+F7PMMzV5NlsbVzy5XKCMZbq8ETEAv28QRuYkpIv2GZv4750SiZs+zrehz/j3NAW6JctmZNTKazYx8e693FpzIiI6x/+ari9rlC65xuXFKvn8bd3gr97ZvOxNo2f2e++jce4vXL7Pr+M+/8/xD3+hn+xlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHVrpPYn2lCRJkiTpyfkXW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKhubCVJEmSJB2aC1tJkiRJ0qG5sJUkSZIkHZoLW0mSJEnSobmwlSRJkiQdmgtbSZIkSdKh/V8BJgHuiAeFRwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_images(sampled_image):\n",
    "    # 이미지를 [0, 1] 범위로 정규화\n",
    "    sampled_image = sampled_image / 2 + 0.5\n",
    "    # 이미지를 numpy 배열로 변환\n",
    "    sampled_image = sampled_image.cpu().numpy()\n",
    "    # 이미지를 (배치 크기, 채널, 높이, 너비)에서 (배치 크기, 높이, 너비, 채널)로 변환\n",
    "    sampled_image = np.transpose(sampled_image, (0, 2, 3, 1))\n",
    "\n",
    "    # 이미지 플로팅\n",
    "    num_images = sampled_image.shape[0]\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 3, 3))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(sampled_image[i])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# sampled_image는 텐서입니다.\n",
    "visualize_images(sampled_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fid score 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Chaehyun/0225_code/git_file\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Downloading diffusers-0.26.3-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (0.20.3)\n",
      "Requirement already satisfied: numpy in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (1.26.4)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (0.4.2)\n",
      "Requirement already satisfied: Pillow in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from diffusers) (10.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from requests->diffusers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from requests->diffusers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages (from requests->diffusers) (2024.2.2)\n",
      "Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, diffusers\n",
      "Successfully installed diffusers-0.26.3 regex-2023.12.25\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/                         new_dataset.py  \u001b[01;34mresults\u001b[0m/\n",
      "\u001b[01;34mdenoising_diffusion_pytorch\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/    train.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/Chaehyun/anaconda3/envs/0225_ddpm/lib/python3.12/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:44<00:00, 1114.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from new_dataset import *\n",
    "\n",
    "data = DatasetSVD('Cifar-10') # cifar10\n",
    "images, labels = data.get_svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset_ae = CustomDataset(images, labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(custom_dataset, batch_size=32, shuffle=True) #, drop_last=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0225_ddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
